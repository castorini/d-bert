{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNF8PzwlEjrUIcUxMPje68T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21395f519bc7450b953df041ec8f2ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0eb24bb03fd4f1e980c9e12408afe3b",
              "IPY_MODEL_7092bdb66e1e433fb224f8424bad1119",
              "IPY_MODEL_87d6be9d3cf640c4a8f504c2f2afb29b"
            ],
            "layout": "IPY_MODEL_c8cfefbc5e06422cae416be042cac1af"
          }
        },
        "a0eb24bb03fd4f1e980c9e12408afe3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f231a754944d2881f3a8e40d056fb9",
            "placeholder": "​",
            "style": "IPY_MODEL_3a5c2751d0cb47f6be5029cc3e670980",
            "value": "Downloading: 100%"
          }
        },
        "7092bdb66e1e433fb224f8424bad1119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e0d449b3f14785a286d0e24692d88e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3234ddf6680c4bc1a540ee82035145ba",
            "value": 1042301
          }
        },
        "87d6be9d3cf640c4a8f504c2f2afb29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a955bfc90b424353a41efe8d5c514864",
            "placeholder": "​",
            "style": "IPY_MODEL_8609499b3b8c46e099f789dff2d77f17",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.67MB/s]"
          }
        },
        "c8cfefbc5e06422cae416be042cac1af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f231a754944d2881f3a8e40d056fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5c2751d0cb47f6be5029cc3e670980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56e0d449b3f14785a286d0e24692d88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3234ddf6680c4bc1a540ee82035145ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a955bfc90b424353a41efe8d5c514864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8609499b3b8c46e099f789dff2d77f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00c5d7fd508d406683895ce05b8c2f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aac417849474a4c9e22a7076ef49d55",
              "IPY_MODEL_0d38dedc87df4381b7a0059b0a6c58da",
              "IPY_MODEL_679f760adbce4a13bd8d60cacd3525fd"
            ],
            "layout": "IPY_MODEL_efe161bb338643e8b9b03288f72f7ec5"
          }
        },
        "7aac417849474a4c9e22a7076ef49d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0c2ccc623247989576a29222958813",
            "placeholder": "​",
            "style": "IPY_MODEL_10b33971cff54af7a27355c847fd9306",
            "value": "Downloading: 100%"
          }
        },
        "0d38dedc87df4381b7a0059b0a6c58da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04442ffa32b14d578c71875529583f01",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43dd6779d7de472cabc0e5802f1d9b28",
            "value": 456318
          }
        },
        "679f760adbce4a13bd8d60cacd3525fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d3bb43b0e141c79a03eab17b735418",
            "placeholder": "​",
            "style": "IPY_MODEL_b5033bed5eac454f9221a699e70a522a",
            "value": " 456k/456k [00:00&lt;00:00, 1.78MB/s]"
          }
        },
        "efe161bb338643e8b9b03288f72f7ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b0c2ccc623247989576a29222958813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b33971cff54af7a27355c847fd9306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04442ffa32b14d578c71875529583f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43dd6779d7de472cabc0e5802f1d9b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d3bb43b0e141c79a03eab17b735418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5033bed5eac454f9221a699e70a522a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f525393d6de49a78b930d34623b6726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829646d41f3b413493f6cf9eb26928b7",
              "IPY_MODEL_feb448d53ae2439ea33a3f3ec40478ce",
              "IPY_MODEL_3f64518b561f4ab3bb75168cc2885686"
            ],
            "layout": "IPY_MODEL_08166a10f1c64d41a28c211df5dbe2ee"
          }
        },
        "829646d41f3b413493f6cf9eb26928b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfe7d249ea3541beb251f8b440e0241f",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ef7de5a91244f5ac164746e14d0d0e",
            "value": "Downloading: 100%"
          }
        },
        "feb448d53ae2439ea33a3f3ec40478ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d56172c83c54a34bd0549234cc31275",
            "max": 718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ed1b2acca4e4a05b74dbdc7c7524753",
            "value": 718
          }
        },
        "3f64518b561f4ab3bb75168cc2885686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b51c3f8939145aab9739ce3f060616c",
            "placeholder": "​",
            "style": "IPY_MODEL_de78874af894491fbe77878c806bd4e5",
            "value": " 718/718 [00:00&lt;00:00, 28.2kB/s]"
          }
        },
        "08166a10f1c64d41a28c211df5dbe2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe7d249ea3541beb251f8b440e0241f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ef7de5a91244f5ac164746e14d0d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d56172c83c54a34bd0549234cc31275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed1b2acca4e4a05b74dbdc7c7524753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b51c3f8939145aab9739ce3f060616c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de78874af894491fbe77878c806bd4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7821af971bcf401caef68ab1b9698db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93a13733429c4ee89fc7e7f0fcea105a",
              "IPY_MODEL_217af3b2653644609f5d70e0a75a3c55",
              "IPY_MODEL_e3d0872ce6854978bda788408a551fc7"
            ],
            "layout": "IPY_MODEL_955815f452d14af1bf7980000b087e2a"
          }
        },
        "93a13733429c4ee89fc7e7f0fcea105a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ef990594334f268bfd0b03c4833c36",
            "placeholder": "​",
            "style": "IPY_MODEL_1d9cc72366954b508654a95b16859941",
            "value": "Downloading: 100%"
          }
        },
        "217af3b2653644609f5d70e0a75a3c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebfcd8ecce9040f98c75637524bf72e6",
            "max": 1520013706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0976ce8f740c48c6ac63cd7bf530785a",
            "value": 1520013706
          }
        },
        "e3d0872ce6854978bda788408a551fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c26058c92214eeb806f70c71d84e722",
            "placeholder": "​",
            "style": "IPY_MODEL_338eb17927f34ae78b333b2298cad9bd",
            "value": " 1.52G/1.52G [00:20&lt;00:00, 81.4MB/s]"
          }
        },
        "955815f452d14af1bf7980000b087e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ef990594334f268bfd0b03c4833c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9cc72366954b508654a95b16859941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebfcd8ecce9040f98c75637524bf72e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0976ce8f740c48c6ac63cd7bf530785a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c26058c92214eeb806f70c71d84e722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338eb17927f34ae78b333b2298cad9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahaShm/knowledge-distillation/blob/transfer-run/transferset_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpNLtzk1XScd",
        "outputId": "c844be4f-cf34-4fb2-cfe7-99b74c676dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.14.0-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model=xxx)\n",
        "set_seed(42)\n",
        "generator(\"\", max_length=30, num_return_sequences=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "zirPwWHih6Am",
        "outputId": "79e90677-5ac8-45d8-d979-0c2ce30c70f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b9a36b29e881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text-generation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmB3dXqhlsaI",
        "outputId": "97e44945-d8ff-448b-ffea-8618de302b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Hello, I\\'m a language model, and the problem we\\'re going to solve is the concept of the \"logical relationship,\" so we can try'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I can be mean like this: \"oh my god I am very bad\", because I\\'m talking about'},\n",
              " {'generated_text': \"Hello, I'm a language model, but, this is a world I live in.\\n\\nI see that my brain doesn't seem to take\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m not going to talk about other languages, I\\'m going to talk about the actual programming language.\"\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, a language model which is not just a binary model, but a model of language data, which is a model\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm a master's in that. So I need to understand what I'm doing… what it feels\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and it's just about what I thought I was having fun learning there. I've made it so easy for\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I like to use those to write functional programming.\\n\\nI've seen this as a common thing,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and a programmer, so while there are a lot of questions at work with a DSL, I've come up\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but this is just the first thing I can teach to developers. Let's walk through why all the different languages\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a webmaster, and I wrote the project to work with the latest development tools. I've worked\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, you ask, because I just put it there.\"\\n\\nHe explained that his goal at the time was not'},\n",
              " {'generated_text': \"Hello, I'm a language model, and how a compiler looks at a representation, we often need some function to look up what that representation means.\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, if not a language model, how can the other people in this discussion have any real understanding of it?\"\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, based on a big dataset and I'll have to work with some different data! What kind of information are you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language. Here I'm dealing with Java. You have a language, you have a language – the\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so we\\'re going to do stuff in an easy way that will do it.\"\\n\\n\"You\\'re thinking'},\n",
              " {'generated_text': \"Hello, I'm a language model, so please check my website…but also: Language and language programming, I use a lot of tools at work\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a very interesting and interesting language. I'll be able to use every single aspect of this language. If you\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a language model, a language model, a language model, a language model\", but a lot of language models'},\n",
              " {'generated_text': \"Hello, I'm a language model, so I would want to write something like:\\n\\n# @param int IInteger(int) number\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not just a programming model.\\n\\nI've always been interested in languages. I got up from college and\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I like syntax but language models are incomplete. For the past couple of years, I've come to realize that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a computer model.\\n\\nAnd you, please, not for a second believe me, this looks like\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I've never made a decision to do a real compiler, as opposed to a real C++ one.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, after all! However, I haven't really done a lot as a programmer yet...\\n\\nI'm not\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, then I\\'m a linguist. That means when you say things like, \"You know, I\\'ve been'},\n",
              " {'generated_text': \"Hello, I'm a language model, which is all right. You can start to play with the syntax. [sigh]\\n\\nC#\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm using a model of a language, and I can only use my own data. We now know how\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I love languages, I like languages, I love languages, I get excited about language models. So in the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a type system, and, as one of my main goals, I want to understand most of this\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and a guy who tries to explain himself and not talk to people. If they are being told what a language\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not an algorithm. What people like me (and others like me) want is more human interaction.\"\\n\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a syntax. This post is a reflection of some of my own work I created. I started with a\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a syntax type in general — I know that\\'s not your job!\" As he replied, he did not'},\n",
              " {'generated_text': \"Hello, I'm a language model, it would be quite difficult for me to work in a real production environment with many hundreds of words in the language\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I\\'m not an idiot!\"\\n\\nThe problem I had with Java 1.5 was the inconsistency of'},\n",
              " {'generated_text': \"Hello, I'm a language model, what did I do here? I had just had three interviews and one show, I was very happy with myself\"},\n",
              " {'generated_text': \"Hello, I'm a language model, an expressive framework that we can work with.\\n\\nIt's in part an attempt to capture these kinds of\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, we\\'re not a problem. Our problem is that everybody has a problem.\\n\\n\"So you know,'},\n",
              " {'generated_text': \"Hello, I'm a language model, so it's an interesting one.\\n\\nWe're not going anywhere now because we wanted to start on the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, that's why you can use a very simple expression to describe a single event\\n\\nTo achieve this, you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming language, just a kind of programming language that provides one or several interesting possibilities with how to think\"},\n",
              " {'generated_text': \"Hello, I'm a language model, just the way it is.\\n\\nWhen you create a document, the user should not only have to create\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language. Well I've made a mistake here, I guess I'm gonna try to be a language\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, which means I get to use almost all the syntax of most of my projects.\"\\n\\nTo do this without'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, you\\'ll understand.\"\\n\\n\"This isn\\'t about the question of \\'what language should this learner learn'},\n",
              " {'generated_text': \"Hello, I'm a language model, but I really don't try and use all the language. I think the language model is much more for being\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I do not belong there. I do not belong there.\" I had to ask this question about the \\'the'},\n",
              " {'generated_text': \"Hello, I'm a language model, which is interesting and interesting to read about, but I won't get into it because I have a lot of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so here I am, trying to tell this kind of story in my own words. I don't do everything\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I tried to look up different languages that have different typefaces and have a common language interface. In general\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I need a way to know how to work with language models - I'm a language model, and that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so this stuff can be pretty much considered an actual language.\\n\\nAnd, because you've already figured out\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so to speak.\\n\\nThe main theme of this story is that we are using the language model, which\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, but you\\'re also modeling things on real-world reality.\"\\n\\nHe adds, \"You think about it'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a world of content, and a world of content but you have just left me,\" he remembers thinking as we'},\n",
              " {'generated_text': \"Hello, I'm a language model, isn't it?\\n\\nWhy would you think so?\\n\\nTo start with, you've pretty much\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I believe that if you're looking for a language, you should get one. The problems with that approach\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, just like the rest of the community.\"\\n\\nIn fact, you can easily add several or more languages to'},\n",
              " {'generated_text': \"Hello, I'm a language model, i can take advantage of other language models to learn them.\\n\\nI'm not going to defend a language\"},\n",
              " {'generated_text': \"Hello, I'm a language model, my language model allows me to think about the whole system, and I can do that with my own data.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you know what, don't you know, I was an experienced designer.\\n\\nP.M.: Thank\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I was born to speak this language, and my mother is a language model. You know. It's\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so, after much deliberation, the first thing is to start by writing an elegant one. An example:\"},\n",
              " {'generated_text': \"Hello, I'm a language model, which is what you'd think; if I'm doing something that you're reading here, that's not a\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so there\\'s not that much to learn from you.\"\\n\\nShe looked back over her shoulder at the black'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I think you need an interpreter that understands the system in question... but at the same time, you need\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, one without a language.\"\\nThere\\'s a strange, unspoken agreement among linguists regarding a common way of'},\n",
              " {'generated_text': \"Hello, I'm a language model, but don't like math. I can't explain it, but this is a very good place to start.\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a language program!\"\\n\\nMy first question was not whether the language model could be implemented by writing language'},\n",
              " {'generated_text': \"Hello, I'm a language model, but your code is a language model. How do I learn this? I want to know: How do I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I think that all of you have probably heard of the LANG system. A linguistic model, which\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I think. It's really about being aware that you're a language model and we want to understand it.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm also a model of a language.\\n\\nA language is a unit that is not a subset\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a scientist and you know what the thing is? The real world is just like that.\\n\\n\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a programmer.\\n\\n\"I do not want to take anything from you,\" Kieb said,'},\n",
              " {'generated_text': \"Hello, I'm a language model, we don't need to reinvent a new word, we don't need to rewrite the syntax of text, we\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I create languages with syntax from scratch and then I come up with the grammar. It means that every line or\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and this is why I'm speaking of the way I see you. I have a philosophy that's hard for\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, but you can\\'t build on top of it,\" she said.\\n\\n\"It\\'s difficult, but it'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, i\\'m a real life example.\"\\n\\nThis new concept of a physical reality is part of why I spent'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language model.\\n\\nDo you want to be part of a language model as well?\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, where I can talk in the world more easily than I can communicate without speaking out in the real world. So\"},\n",
              " {'generated_text': \"Hello, I'm a language model, in my writing. And I wanted to write what, if I looked at someone and said 'This will be\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I was trying to take a little bit of its 'why' and not a lot of any of it really\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I want you to understand how I was able to understand all that.\\n\\nI was looking out at\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I'm not sure if you could make me a language model, but I would love to learn more.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I use languages. However, what can a language model in other languages do as well? I want to do\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and you can use the Model of an object. But let's see how to do that. You can start\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a programming model,\" he said. \"You don\\'t see it. You\\'re in the programming world,'},\n",
              " {'generated_text': \"Hello, I'm a language model, meaning that it's possible to see patterns in the data, not just in the languages. It's useful on\"},\n",
              " {'generated_text': \"Hello, I'm a language model, that's why I'm here, where what's being studied, what's being developed is what is at our\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and the problem is you don't want to call typeclasses with type-safe functions - but you do so\"},\n",
              " {'generated_text': \"Hello, I'm a language model, with the goal of making my languages as elegant and readable as possible. And speaking of the language model, I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a theory. And if I wanted my language model to be wrong about grammar, how about one of the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a text model\\n\\nI've never made a system that accepts a newline character (except for code\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language of letters or numbers. The most important thing is that our models take these sorts of concepts seriously\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I think that. I'm trying to explain how the programming language works in a declarative fashion at the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a language model. You are not just building a system for your own benefit, you need to keep in mind\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I think. So I'm very excited. What's the point of having a single language? And what is\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a system. I was a language model. What the fuck is that?\"\\n\\n\"The model,'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a function model\\n\\nTo create a language model, set the value to the set of function values that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I won't go on about what my own language is, but let me know if you have any questions\"},\n",
              " {'generated_text': \"Hello, I'm a language model, don't you think? Well, you're right, I'm not saying you'll ever learn any more of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, an object model, an object model that can look something like this:\\n\\n# Create a view for a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a model of computer programming. Instead I'm a model of physics in which all the pieces are connected,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm also a writer, a computer game developer, I write a lot of visual, mechanical stuff here\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a text model, a set of models, a series of equations, you can do anything you want.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and my work is pretty much the same, so please don't hesitate to tell me what you come up with\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm not a programming model, so here you go:\\n\\nclass GameContext { public: Game\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so you're going to want to use a certain type of interpreter if you're starting out, like if your\"},\n",
              " {'generated_text': \"Hello, I'm a language model, it's all about building things. The first step is using syntax and syntactic sugar to express the code that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you know. I've wanted to write an entire book about languages, and I've been working on it.\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I\\'ll teach you how to use it in my next course.\"\\n\\nIt\\'s not nearly enough that'},\n",
              " {'generated_text': \"Hello, I'm a language model, and you have a friend, an academic, that speaks fluent English that can understand your code or a computer interface\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, or an expression model for you, please tell me how it works and you\\'ll know what it does,\" she'},\n",
              " {'generated_text': \"Hello, I'm a language model, and languages are not magic magic. I don't know how to write a programming language. I guess I'm\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a model-builder. I love a good language model. I want to write it!\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but this week I'm going to try to get this stuff into my head as a model.\\n\\n\\nWhat\"},\n",
              " {'generated_text': \"Hello, I'm a language model, like so many other writers. I love to write like the kids I am at home with, and to explore\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so the idea of something that I'm writing a language model seems to be a nice thing to ask, but\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and that's the best I get. Anyway.... You know, it would make sense if I could see your\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a code model.\" Even then, with a small bit of insight, a model\\'s language was more than'},\n",
              " {'generated_text': \"Hello, I'm a language model, but your language model cannot be a model for something like Ruby.\\n\\nWhat's going on with your C\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I do have a job.\"\\n\\n\"A simple system of languages does that! It\\'s much easier for'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a coding model,\" says Raghu Vaidya, author of the book \"What C is For'},\n",
              " {'generated_text': \"Hello, I'm a language model, the same as I am right now, as the people I write my languages for. I want this to not\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and a learner. It's my job in a language model to teach you that knowledge. It's my\"},\n",
              " {'generated_text': \"Hello, I'm a language model, my code is written in C, so everything is in C. If someone asks me what C is and how\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, that we created for people who want to solve problems for themselves.\"\\n\\nOn the other end of the spectrum'},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm not a machine. I'm not a language.\\n\\nI like language models. How can\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and this is great. You may ask yourself why I am doing this. I don't know. I have\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a human model. People ask me: why do you even need to think about languages, right? The\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, but really you write my code, then let\\'s go with our data type, like \"myText\", and'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I love a lot of writing. You see, while writing a sentence is useful in describing the actual type\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and if you put your imagination to the test, you'll figure out the best way to convey meaning in your\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, that\\'s easy to write in any language and to actually understand,\" says Dr. Daniel Bales, former Chair'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a programming language.\\n\\n\\nA \"language model\" is a way of saying something that doesn\\'t appear'},\n",
              " {'generated_text': \"Hello, I'm a language model, a computer program. That's my whole job—I'm not a compiler and I can't make those machine\"},\n",
              " {'generated_text': \"Hello, I'm a language model, i.e., A language is one thing, but what does your role in thinking about languages mean in this\"},\n",
              " {'generated_text': \"Hello, I'm a language model, right? And my big question here is: why do we have them in the first place? It's because\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m a learner of languages, and you\\'re telling me you don\\'t have a real language?\"\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, I do all programming, I do all writing, I do everything from code to writing in PHP and now you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I've never done such a thing.\\n\\nCannot test for errors because there are multiple versions\\n\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a language,\" he says. \"Why would I want to have a problem when there is no language at'},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm not writing a very complex and very precise language.\\n\\nThat's why I write. In\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm not writing much.\\n\\nSome of its features are simple and not very important, such as\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a real one: I want a good design for both a real-world API and a real-life application\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I like to make mistakes.\\n\\nMost commonly, the language model is set to a predicate.\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, too. However, unlike a computer, I don't want to spend hours writing a big blog post on a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and that includes the syntax. You get what comes from a model like the LESS, but if you are\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m a science.\" The other part of the question I asked was how would other people perceive your approach.'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I make that data easily easy.\"\\n\\nThat\\'s because while many of us make sure that we choose'},\n",
              " {'generated_text': \"Hello, I'm a language model, and like an engineer, I'm trying to capture the same logic to every user. I don't like to\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m just using the Java APIs,\" says Mr. Ritchie. \"But then, like any programming language'},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm actually an engineering model for the system. So I think it is the most important thing in our\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm a machine, and I'm a computer, and we're learning from each other, so one\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'd like to introduce my new name in case you want to know what I do.\\n\\n\\nIf\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I love to talk about and to teach myself, but after reading the words they just made, I can't\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but maybe a better term is human capital. This is where a human will see that he needs to be able\"},\n",
              " {'generated_text': \"Hello, I'm a language model, i mean you have to think about how to deal with other human beings, not only people, you have to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, my only programming skills are in PHP and J1SE but that hasn't stopped me from working hard at it\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a designer, I'm a designer of code. And I have this kind of relationship, you know\"},\n",
              " {'generated_text': \"Hello, I'm a language model, it's very nice to listen in and get up to speed with your code. I like to use these frameworks\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I can learn languages much more at home than you. My philosophy is to go the whole hog, to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I've had other things on here, but I'll stop for a little while and say something that you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I don't feel like such a good model, let alone a good programming language. If I'm going\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I am, I'm a problem solver. In my view, I think one of the things that language\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I can understand the language, but I can't really teach you all your programming.\\n\\n\\nHere's how\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a system model. Language models are really only about modeling the features you can think of, and not about\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not some kind of language model. I think I speak Java, but I'm not a programmer.\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and can make simple JavaScript web applications (if you like), then by using C# and C++ you can\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not just a computer.\" And now she says, \"Oh, I\\'m actually pretty nice... it\\'s amazing'},\n",
              " {'generated_text': \"Hello, I'm a language model, so I am not as well-known for my knowledge of logic, but I think it gives me a good\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I know that people in these forums are interested.\\n\\n\\nOn the other hand in doing this I learned\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you see, language modeling is very important. For me, it has really big implications for other languages. For\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and like in the past I'm using Python to build software projects, but now with the Python ecosystem, where\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a framework for the implementation of a data set. I hope the following will prove useful: If you have seen\"},\n",
              " {'generated_text': \"Hello, I'm a language model, if we could write an object model in Scala, it would be really good, I would see the benefit of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, one of a very small species of monkeys. It is in my bones. And that's all I ever want\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm here just to say hello. You shouldn't waste your thoughts like this. I don't like\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but what about you? Why don't we just go over the main interface for you?\\n\\nIt might\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a compiler.\" (I have to say, I\\'m a software engineer).\\n\\n\\nSara H.'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not software model,\" he admits. When programming is too hard, he says, programmers stop. His point is'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m not fluent in that! I don\\'t even have a computer!\"\\n\\nAfter a pause, he'},\n",
              " {'generated_text': \"Hello, I'm a language model, which means you have to use all different types of data. In a world that requires a large number of databases\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language problem, but rather like a problem where I want to learn something about it that I can learn\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and a programmer. That way we can have multiple languages interact.\\n\\nOne of the most interesting features of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I've studied, I know all sorts of languages. If you asked me as to why I'm a language\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a model of understanding how people do things. I'm a learner. And I know how to use\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm trying hard to teach my students that you have to have a language when you are writing and to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, let me get my hands on a TensorFlow machine, using my favorite image engine called TensorFlow.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming language.\\n\\nWhen you see me, you know it's because he's a student from\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I really want to understand your thinking, and you're on the phone right now in Berlin. (laughs)\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I like to define, you know how to handle your models in a program by giving an order, something\"},\n",
              " {'generated_text': \"Hello, I'm a language model, now do you know what a grammar is? It's just a set of words, the most basic of which\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I am now working on a language design framework for Scala. I want to add more functionality by adding more\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I don't mean one for every language and every toolset or framework. I mean languages that give you\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, like so other \"real\" languages are, that\\'s how it\\'s meant to be. It\\'s like programming'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I think I'll do a lot of the thinking that does the work for me. I'm really excited\"},\n",
              " {'generated_text': \"Hello, I'm a language model, it's my best tool. I am very much inspired by the fact that we all use and like language models\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I am still stuck with English when it comes to grammar and semantics. I will try all over again.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a data model.\\n\\nA language model was created to reflect the complexity of an application's user experience\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, which helps us understand how languages work.\"\\n\\n\"Language models help us understand how systems work. They can'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I know that if I don\\'t do this one, it will be useless.\" And so the problem became'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, but I want to make it sound like the actual language does the talking when I\\'m talking.\"\\n\\n\\nHe'},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a model of human action and I'm the human of what to say.\\n\\nHow you think\"},\n",
              " {'generated_text': \"Hello, I'm a language model, right? If I go out of my way to describe my writing or my personality well, I'll be fine\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a syntax model, and I know how to write code that works in Python.\\n\\nSo now\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a model to be emulated in one's mind (as there are many). I am a model of the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language designer. I've seen many languages being used for things like web and in-person sessions,\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so now everyone gets it, you know?\"\\n\\n\"It\\'s a good way of saying, \\'You'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a function:\\n\\nMy function would be my function and the code would be a generic function.\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm not a code model. I don't understand the context of the language. I don't understand\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I've used it in a number of languages. If you want, you might need to implement one of\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a programming model of programming,\" says the German-educated engineer.\\n\\nYou may well imagine it as the'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I've learned a lot about writing great code.\\n\\nWhat are some basic concepts of writing beautiful code\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and as such I know its pitfalls. I will say, I see the value of an open source model,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a system. What my language is, I've learned through experience. And I think this is where I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a code generation tool: the point of my project is to learn it and use it in my own project\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a language builder\"\\n\\nIt could be argued that we have become too accustomed to the concept and that'},\n",
              " {'generated_text': \"Hello, I'm a language model, and the point has to be that all languages have to deal with it. So it's not enough that the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a model of how humans, and everything else human can be.\\n\\nIt's true. What I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a person. Because I'm a model, I can't explain them so simply. It's something the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but some of my models need a certain kind of language. We need to know how to represent it and how\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a code generation tool…\"\\n\\nIn my earlier days I would have thought I was at the pinnacle of'},\n",
              " {'generated_text': \"Hello, I'm a language model, language models are what I'd call the foundations. I'm just trying to find the right balance between these.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'd like to give you some thoughts to help us introduce it to your computer. So, let's\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm pretty sure everything we've ever done in this universe will be implemented in this framework by the next\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I guess that's fair. As a kind of a general point, you know, if that model can\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I was an amateur on Java back in the day. My father was an engineer and I was a computer\"},\n",
              " {'generated_text': \"Hello, I'm a language model, my role at the moment is to see what the language design is coming to and, eventually at some point,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, meaning human-level analysis and optimization (also known as human-directed algorithms)—there are two basic classes of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, right?! Well, at least I'm an ass. But then, why am I still studying my languages as\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I understand that languages are languages. They're not just words, they actually mean things like words.\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a model program. I really think people should consider that before they jump to reading something like the following and\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and it really hurts. I tried to make things nice for the people who are very close to me. But\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I am also an actor. So, I feel like the actor is a player.\\n\\nMy career\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I think that's all. It was very popular as a kid, but now it seems to become like a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and so it's time to start teaching you how to write in it and I'm going to talk so much\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I need to keep track of when a process needs to be updated and when it needs to shut down.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, for an imaginary computer in my classroom. I'll tell you the full story of how my game is written on\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, or at least model that people call models.\\n\\nThe \"normal language\" is a big one. It'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I can handle multiple languages.\\n\\n\"Why did I ever use JavaScript?\".\\n\\n\"Why use'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, what do you mean?\" I ask him. \"What languages are you a programmer on? Which languages have you'},\n",
              " {'generated_text': \"Hello, I'm a language model, a programming model. I'm not saying this and I'm not doing any of this; I'm just saying\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I am more than proficient when I need to understand languages. One key point is that I don't really understand\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a program model, and I've used the programming model to make good decisions for my computer-generated\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm part of a team, and this project is about teaching people how to build a system that can get\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, now I\\'ll look for a good one.\" He had a bright smile and a very nice looking face as he'},\n",
              " {'generated_text': \"Hello, I'm a language model, after all. A grammar model in its purest form is often used to explain and support the structure of language\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a person whose own body I call the \"face\" of the whole \"my\" world. But I was'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a model of the world. I didn't just write a grammar, I took part in a real world\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you see? It sounds simple, but I'm very serious.\\n\\nFirst off, you should do your\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and so the same is true of JavaScript.\\n\\nWhat might I do?\\n\\nWhen I first started\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not an environment model.\\n\\nBut I've also said something I haven't seen before, which is why\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I use language models of learning. However, most of what I have written about with language models is still useful\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a kind of language model of what a language is. This is something that I'm kind of interested in getting\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so it is nice to hear people talk about my ideas (e.g. in Java).\\n\\nThis\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and when I learn it, I'm going to know where to go next. If I don't know where\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I just made a nice post today about the idea of a parser that can do things a little differently.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, right?\\n\\nI used to love it when I was in high school, but now, there are a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a project manager… I've been very fortunate to get a few mentors, I came from a family of language\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I used to be a language model myself, but when I had no other way to express my beliefs,\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, but I\\'m a person who knows the language quite well.\"\\n\\nTo paraphrase Bill Gates, I am'},\n",
              " {'generated_text': \"Hello, I'm a language model, you see. Your first project will be a library called tbcm. It won't be much more extensive\"},\n",
              " {'generated_text': \"Hello, I'm a language model, yes of course. But what really matters, is what you are trying to explain. In short, what is\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I never wrote something like this. I only want to communicate with you so this will be fun to experiment\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm pretty good at it. But for those that are interested,\\n\\nit only has one parameter,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a set of idioms. Language theory means, we try to think about things in terms of the rules\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm not trying to be a language-modeler, but I'm trying to learn something, so\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language designer; I don't have much in the way of experience with syntax, so I tend to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, as is the whole Internet. I was trying to write this for my own personal project. It was a great\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I wanted to be able to create code within C enough to solve our current problem. In particular I want you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, too.\\n\\nI'd use the concept of the new syntax to explain a particular feature of the object type\"},\n",
              " {'generated_text': \"Hello, I'm a language model, let me show you what kind of system is here.\\n\\nBut let me get back to the first point\"},\n",
              " {'generated_text': \"Hello, I'm a language model, as you know my first programming was for building web pages. The web web, and the mobile web. The\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I have no idea what I just did here... I don't know how that's going to be the way\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a programming language; I\\'m not a programmer.\" I\\'m looking around me. That was it.\\n\\n'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so I\\'m a \"type of problem\", so there\\'s no type of problem and only kind of a type'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a writer. When I\\'m playing through \"A Good Day to Die,\" the characters of the movie and'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I use it as a model of what it means to be a language developer. I work at the University\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language. What I do is, I want to be a language model. So, I've learned\"},\n",
              " {'generated_text': \"Hello, I'm a language model, one that you can write and use, but just like any other language, we need to create a model for\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming language.\\n\\nYes!\\n\\nHow'd you come up with the name of your most\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so I\\'m not used to talking about things like syntax and syntax-based systems.\\n\\n\"This sounds'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a game model, a video model, a design model and I think a good question is, \"Can I'},\n",
              " {'generated_text': \"Hello, I'm a language model, let's build this new system:\\n\\n(defn build-core [hq] (when (>\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so if any of this sounds like it might be a very good idea to start with a simple model you can\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, too.\"\\n\\n\"I wouldn\\'t say I\\'m a programmer,\" she replied, and went on. \"'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a data model. Well, like in any system it's hard to explain what's going on and we\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, too, but I also have a little more control, and therefore more control with things like programming.\"\\n\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, my head is just doing good. I'm thinking of writing Python. Then I should probably play a game of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, this is a part of your language, it makes sense to me. In what circumstances need to create the appropriate\"},\n",
              " {'generated_text': \"Hello, I'm a language model, which requires a lot of memory, but I'm a functional programming learner. My main goal is to understand\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you tell me what I want it to do, and you say it.\\n\\n\\nI didn't make the\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a product. For all those who haven\\'t studied the term, we often hear, \"So, you'},\n",
              " {'generated_text': \"Hello, I'm a language model, but not as simple as you'd think. I think I got myself as far as a language model out of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not an object. Why do you feel comfortable writing such a language model? Because most of the time you can\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, what\\'s that going to look like?\"\\n\\nJohansson: \"Yeah, that\\'s pretty much all'},\n",
              " {'generated_text': \"Hello, I'm a language model, I use Java for my programming and I like Java for my programming experience, even more now because I have not\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I'm not going to say that I'm a programmer. I'm an artist. And I feel that\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m a way to explore new ways of thinking\". A lot of people use this language model, but I'},\n",
              " {'generated_text': \"Hello, I'm a language model, and there's a great deal of wisdom in this area. We've been looking into things like the code you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so you can imagine the experience at Google I/O 2014. I think we are the best of the best\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and it really doesn't work. I'm a native, so don't worry about it. It could be\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a software model. We're programming on a large scale and there are more that can be done which isn't\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so it's easy to grasp the semantics of a particular object.\\n\\nSo, let's understand a specific\"},\n",
              " {'generated_text': \"Hello, I'm a language model, because it happens at least as much in the real world as in programming, but there we go again.\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a language that describes behavior in Haskell: I know how to have an arbitrary number of actions (like typing any\"},\n",
              " {'generated_text': \"Hello, I'm a language model, right? I'm making things for a community. When my dad taught me to speak something, I grew up\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and this is something I\\'ve been thinking about for a long time now.\"\\n\\nOne of the big questions'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I didn\\'t do it in a year, that\\'s fine. I have learned things there, there.\" \"'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a language model, and I don\\'t write languages because I don\\'t believe in science,\" says Giff'},\n",
              " {'generated_text': \"Hello, I'm a language model, so here's how I would describe it:\\n\\nclass Meta : Mutation { def readFrom(self\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I don't care how many speakers I have. I should just have my own language that is compatible with\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a framework, I'm a system, I'm a product. I mean, I can say anything\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a function model, I'm just a language model in a way, I can help you.\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I actually write in an editor, which is where I really learn. Also, we've always had some\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I want a programming language with a pretty good pattern. The code is more than what we want and the models\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a coding world, and so I can't really talk about all the things that go on. That's\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a philosophy teacher.\\n\\nI'm not the first person. In some ways I'm the first\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I'm sure you can pick up on any of the principles and techniques on how to build a language model\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I know how to create this. [laughs] No, no, never in a million years. I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I do not have any formal skills. However, even if you can write any language model using this, you\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I\\'m working from it. [laughter]\\n\\nWe were talking last week about my new book, \"'},\n",
              " {'generated_text': \"Hello, I'm a language model, no need to write a function for this. I'm just happy you know that I can also call this code\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but I don't know how to use Lisp?\\n\\nYou never know what can get you into trouble.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, how do you like it? It's a good question, but why is it the only language I'm using\"},\n",
              " {'generated_text': \"Hello, I'm a language model, isn't it? I've been making this a long time, but I still haven't seen a lot from\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a product model.\\n\\nYou know what's more impressive in the world of programming languages is that there\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming model.\\n\\nI'm really interested in what language models can do, particularly when you're\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a programming model. This isn\\'t a \"me\", I\\'m a programming model.\\n\\nDo you'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a philosophy. Instead, I make some suggestions about what languages I can help implement.\\n\\nFor today\"},\n",
              " {'generated_text': \"Hello, I'm a language model, this is actually where I make my predictions. This is where I try to show people the best practices and methods\"},\n",
              " {'generated_text': \"Hello, I'm a language model, language model, one who thinks that language models are good for writing code. One such language model, that,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programmer. What does that have to do with the programmer? I'll get the answer.\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and it was pretty simple to understand as a beginner for me. I guess you could say that when I first\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I wanted to make some code that shows that this is very popular, but that in fact some other languages\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but that means that there's a lot out there that can actually be considered a non-intended-by\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I have this idea about all the objects.\\n\\nSo now you know which are the ones you want\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a tool. I want to become a model,\" Dr. Leng says.\\n\\nAfter three years'},\n",
              " {'generated_text': \"Hello, I'm a language model, but if I talk about you at all, what you say isn't actually true. It looks like you've\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and the people who want to write good books about languages do. If you have any interest in languages then I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so let me give you an example; say your UI component (not that it has any data. It's\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language.\\n\\nThis is where I made the mistake that I had for the first time a while\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a language model who uses the programming language Lua and wrote a programming language, because I thought about the complexity of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not an ideology. I'm not a scientist. I can't put more words in my mouth. I have\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm not perfect. My theory for how to write a nice grammar for a good language is that it\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and can create pretty simple objects but just need a way to look like an interface which I can use. Then\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'll solve your problems.\\n\\nYou're probably pretty hard-pressed to describe the problem of building a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I want to be able to write good code. I've never been a programmer, but when I started\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I was inspired by the OSCI-9 project, and I think its quite simple. It's not\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm still working on my master's thesis. My next project is actually about this new field of computer\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a language,\" says John Czobów, a Polish-born American whose house in Pittsburgh was'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a game.\\n\\nNow, I think this is interesting to you. I'm curious who that language\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I want people, people to understand you, all the while, making this journey in the world.\"\\n\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, I believe, of the whole human being. It's the essence of language, and I believe I have done\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I do not know how you will communicate with me.\"\\n\\n\"I only understand it one bit, I'},\n",
              " {'generated_text': \"Hello, I'm a language model, not the same as I thought it was! I'm using PHP, which is more than good enough! I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I can do whatever I like with languages. The key to being smart about languages is knowing how languages work\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a computer, because I think that we're all part of something: not just our words and actions but\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and that's why I wrote this article.\\n\\nSince its inception, we've noticed that the idea of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so you should give me a solid description, and I'm sure there will be someone willing to do an exhaustive\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a way of talking to a computer and my brain's ability to control its operations. Now imagine I have a\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not an interpreter. I don\\'t write a \"language model\" in Python because it is extremely expensive and can'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I have a bunch of interesting things to say about it. In general, they are going to sound pretty\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I don't understand any language besides Hebrew. Anyhow, there's another article about language models, just want\"},\n",
              " {'generated_text': \"Hello, I'm a language model, which means when I wrote a model, I am using an expression where there is nothing you do. So when\"},\n",
              " {'generated_text': \"Hello, I'm a language model, for the last five years I have spent four years writing and performing at the National Institutes of Health (NIH\"},\n",
              " {'generated_text': \"Hello, I'm a language model, the idea of creating an API. Let's walk through what we want.\\n\\nThe data structure\\n\\n\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I think I can teach you some things, if you\\'re willing...\"\\n\\nShe said, and after'},\n",
              " {'generated_text': \"Hello, I'm a language model, but you guys know I love it. In my own mind it's pretty easy to describe just enough to help\"},\n",
              " {'generated_text': \"Hello, I'm a language model, my brain has been designed so I knew the rules. The one thing I had not used before was my eyes\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but my point is that the main way to define the data for a language is to write it down. To\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not just a programming language...\"\\n\\n[12:09:52 AM] S.Daughter: you'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, too. Just want you to get used to it.\"\\n\\n\\n\"Well I\\'m a teacher, too.'},\n",
              " {'generated_text': \"Hello, I'm a language model, but it turns out I'm a really nice guy.\\n\\nI'm not sure why most people say things\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a theory of language. I want to write language that is a language model for the real life human being,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and writing functional programming languages is like working in the car. I can change the direction of the world by saying\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a language model that helps me with what I want the world to look like. I can say that in our\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a formalization. Your language model's just an idea-measurement machine. What does your model\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and it is not possible to make a model that works well while you're using a framework like Haxe or\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, no big deal. I\\'m just doing my own things and I just do things,\" he said.\\n\\n'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, you have to know what I mean. I do not even know where I will speak.\"\\n\\n\"I'},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a programming model.\\n\\nI want to run an image at a large scale. So one thing\"},\n",
              " {'generated_text': \"Hello, I'm a language model, one that is a lot of work for a computer. The more you understand Python, the better you'll be\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and it doesn't matter what you wrote or what project you worked on. You can say something that everyone understands\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so this page might not be that informative to you!\\n\\nSo what is an LISP?\\n\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a language.\"\\n\\n\\nThis was the first of many speeches to his audience after he delivered the keynote speech'},\n",
              " {'generated_text': \"Hello, I'm a language model, not an ideographic system. For example, imagine that we were to learn about languages, about history, about\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so let's talk about what that means.\\n\\nSo how is it that languages with common features, such\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a programming language model. I'm the program model for a real computer. My model is the programming\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but a good language model doesn't always look like the best. Why do some of my languages fail at a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, as are your two. I'm a writer because I have to, and I don't like people's opinions\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I don\\'t think you can understand more than that.\"\\n\\nIn the meantime, an English model of the'},\n",
              " {'generated_text': \"Hello, I'm a language model, I wrote my own rules using the compiler.\\n\\nThat's pretty standard stuff, but it's just a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I don't read anything in Chinese. But why not? Why don't I come to study for a\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I also want to see a lot of languages develop into languages. The way you play in this world is\"},\n",
              " {'generated_text': \"Hello, I'm a language model, as my job is to create interfaces. And I want my data to work together as well. I want it\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and the only thing I really really need are to know about programming and languages for languages (I've taught people\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I think that's great!\\n\\nWell, I guess sometimes we just don't have time to talk\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and that's why I want to create another one. This time i will create a grammar, to allow you\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a person.\"\\n\\nThis year, many of the world\\'s most famous and celebrated languages will launch their'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a model of a social network\".\\n\\n\"I\\'m not saying nobody should say it\\'s rude to'},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm also a programmer. There's no better way than to have a class which you can easily build,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a computer model. (Laughs)\\n\\nI guess what my goal is isn't to teach you how\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but it will come out very quickly. I've been doing such a good job keeping in mind the language model\"},\n",
              " {'generated_text': \"Hello, I'm a language model, as well as an interpreter… But sometimes I'm doing just one thing. I need to help you understand languages\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so this is not the first time I've played with the same model. That one, I guess the code\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, this is what I\\'m looking for!\"\\n\\nHow\\'d you get started with that? Did you think it'},\n",
              " {'generated_text': \"Hello, I'm a language model, and a pretty special part of one.\\n\\nFor over a decade I've worked in data visualization and data\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a designer... I\\'m a person. I\\'m a person. But I\\'m not a man.\"\\n\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming one.\\n\\nThe most important characteristic of languages is its syntax, and you will find these\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a model of language models that are trying to express, what are the kinds of things that are happening\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so you have to do the exact same things, but with lower-level language abstraction. So, it just\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and you understand, well, not that I understand. I'm a model like any other, and I believe\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I make a lot of assumptions and, you know, I don't know, but I know it's\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not quite a compiler but quite an interface. I've done almost everything I can to take that concept of the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a functional model for programming languages, and in this paper I bring the same principles to Haskell so that it gets\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I create the models on top as a way to help to solve problems. It's possible to use my Python\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so I have to deal with the constraints of what your application wants to do with this program.\"\\n\\nAnd'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I think this blog needs a big update. I'm going to focus on this, and it's going\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming language, just a tool for the job. I don't know which of those can be counted\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you are a language model, I know your code.\\n\\nI said that, let's implement your code\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a programming language model, I'm an implementation of a Turing machine, etc. So the idea is\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a type-checker.\"\\n\\nA little while later, when asked to describe the work in detail'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming language. I never used to be writing in C, but it still works. In Java,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I just learned about it yesterday. I'm not a writer. When you look at your life as a computer\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a model which takes into account complexity of expressions, including how we can handle expressions that require specific language features.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm designing a program. If you don't need the system, the syntax is in front of you now\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and when a program reads its part, the part isn't fully parsed, but you're free to make your\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and in the next post will walk through all the questions I have with your language model.\\n\\nThe basic\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a programming language.\"\\n\\nShe pointed to the language\\'s new documentation.\\n\\n\"You can call'},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'm so excited to get to writing one of the best languages I've ever written.\\n\\nAnd\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a language model that can deal with complex ideas and complex solutions.\"\\n\\nThe question was asked by Richard H'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I can do anything, and I want to know the language as well as the user.\\n\\n\"'},\n",
              " {'generated_text': \"Hello, I'm a language model, where I'm defining a model, what's happening in a model, and a thing that happens, something that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a computer and so there's a lot of language I want to learn…It makes the world a better\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I use my own framework, we\\'ll see how that goes\", she said in return, \"I believe that'},\n",
              " {'generated_text': \"Hello, I'm a language model, so I don't know that I really do know if there is a language model that can be developed from a\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a person.\" - He\\'s like those words,\\n\\n\"Hey look I said something. The whole time'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, a language model, a language model, a language model,\" says Bostrom. \"Language is an essential'},\n",
              " {'generated_text': \"Hello, I'm a language model, too. And I'll tell you that I made three different projects when I first started writing this: In the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and my goals for life are not to understand what the world needs to do. These are also not my goals\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm trying to write the same code over and over. This is part of the problem. So, you\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm not a science, I don't have my own world. I have my own language, but I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not an algorithm. (I use Perl to create the language model—I'm building an interface to do the\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a programming model. I'm not using a computer, but a piece of code is being run. And\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a model of the past and future. It has to be as well-thought out and intuitive of a framework\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language model. To understand my position, let's look at the syntax I use in Scala. I\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, my language is based on C++, Java, Python,... Well, what\\'s happening in terms of \"'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a person...\"\\n\\n\"And if I did that I could get the best of them...\"\\n\\n'},\n",
              " {'generated_text': \"Hello, I'm a language model, and if something like this is too hard, just make a new one.\\n\\nI don't think it\"},\n",
              " {'generated_text': \"Hello, I'm a language model, but can you help me introduce it to me?\\n\\nThe best thing about the language model is it is\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm not the developer of any language, I'm not the author. I've done my own creation,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a functional one at all, and I've already talked about functional programming a bunch. My goal is to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a functional language model, and you'll recognize that in my opinion. When you think about it, it\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you'll hear it when I get my hands dirty.\\n\\nThe realisation is that the only way people\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a person.\"\\n\\n\"A language model is an algorithm for a particular kind of information that you don'},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I don\\'t write code like that.\" But, he says, I could write a program and then not have'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a language model.\\n\\nWhat if I had a language model with a language model with one object that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and that's how I learn about programming. This is a different world. You are looking at a world that\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm a user, a person.\\n\\nThe user isn't that much different from a human, and\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and so my question is how to interpret this, if you don't have a good way to read and write\"},\n",
              " {'generated_text': \"Hello, I'm a language model, well, it's a programming language you understand. And if you're an expert on it, this should teach\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, I am going to show you how I built a program, which is an OOP program.\"\\n\\nOn'},\n",
              " {'generated_text': \"Hello, I'm a language model, so I won't go in-depth with the programming language details here.\\n\\nIt is possible then to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a set of programming rules, a set of objects, a set of functions as functions that you must do in\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, but it\\'s easy enough to make your own,\" said Mark J. Stuckart\\'s daughter Marla.'},\n",
              " {'generated_text': \"Hello, I'm a language model, not a computer.\\n\\nWhat is it like to learn to speak Java?\\n\\nJava is very exciting\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I'm in control of what language model to use. It's not my fault if the first language model\"},\n",
              " {'generated_text': \"Hello, I'm a language model, with no actual programming experience and my own experience of interacting with language design.\\n\\nWhen you build an object\"},\n",
              " {'generated_text': \"Hello, I'm a language model, though.\\n\\nThe primary features of my new C# application are:\\n\\nAutomatic programming\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I think a lot of people talk very much of a C++ language model. And I think there are\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not just a programming language, though at least one (or both) had its origins in C. It may\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I write for games, I make videos for a wide range of things that I like to do.\\n\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I think the code for this is pretty intuitive, and it's really hard to imagine it will be completely different\"},\n",
              " {'generated_text': \"Hello, I'm a language model, well-documented, and simple. In other words, I'd like people to recognize the importance of their languages\"},\n",
              " {'generated_text': \"Hello, I'm a language model, where you can interact with objects and interact with data from other users' devices with a language. If I'm\"},\n",
              " {'generated_text': \"Hello, I'm a language model, so I might have slightly different expectations when it comes to coding and teaching, but for simplicity, I had to\"},\n",
              " {'generated_text': \"Hello, I'm a language model, the way I'm looking at it is that we're building a new language where it would be easier to make\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a system analysis model, a web development framework, so to speak. Some of these things are part of my\"},\n",
              " {'generated_text': \"Hello, I'm a language model, which means, of course, that I'm going to learn every language, just by seeing how things come together\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not computer programming or anything. It is an intellectual world, without computers. You are not going to be able\"},\n",
              " {'generated_text': \"Hello, I'm a language model, a model for real-world programs you would like to have, like a tool for doing this kind of programming\"},\n",
              " {'generated_text': \"Hello, I'm a language model, you can use it as a programming language. What's your definition of a language model? The language model does\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, not a programming one,\" he explains.\\n\\nGrundy doesn\\'t think I can say a thing'},\n",
              " {'generated_text': \"Hello, I'm a language model, but if you take a look on the top level of the OOP project, there aren't many things you\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, and I think that all the things are right and wrong.\"'},\n",
              " {'generated_text': \"Hello, I'm a language model,\\n\\nI am a text model\\n\\nI am a semantic model of the world\\n\\nI am a\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, how could you not understand my language?!\" she wondered.\\n\\n\"Well it\\'s just, what is your'},\n",
              " {'generated_text': \"Hello, I'm a language model, to answer your question you have to understand my experience with writing in a language.\\n\\nWriting all kinds of\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I think I'm pretty cool. When I'm writing my own code, my language is the language. I\"},\n",
              " {'generated_text': \"Hello, I'm a language model, which means that I make a model of your language.\\n\\nA model is a model of your language.\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm teaching you that, but I didn't say you can do something like that and you won't win\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I build models from data. Data is the key to the knowledge that comes with the language. You know,\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm talking about things that are not represented outside of the language model. One of them is syntactic prim\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I have a basic programming brain, I know what I'm doing. I'm sure there will be some differences\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "henyJueJYAlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "\tdef __init__(self, data_file_name, data_dir='./'):\n",
        "\t\tsuper().__init__()\n",
        "\n",
        "\t\tdata_path = os.path.join(data_file_name)\n",
        "\n",
        "\t\tself.data_list = []\n",
        "\t\tself.end_of_text_token = \" <|endoftext|> \"\n",
        "\t\t\n",
        "\t\twith open(data_path) as csv_file:\n",
        "\t\t\tcsv_reader = csv.reader(csv_file, delimiter='\\t')\n",
        "\t\t\t\n",
        "\t\t\tfor row in csv_reader:\n",
        "\t\t\t\tdata_str = f\"{row[0]}: {row[1]}{self.end_of_text_token}\"\n",
        "\t\t\t\tself.data_list.append(data_str)\n",
        "\t\t\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data_list)\n",
        "\n",
        "\tdef __getitem__(self, item):\n",
        "\t\treturn self.data_list[item]"
      ],
      "metadata": {
        "id": "pGc64As6SHuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(data_file_name):\n",
        "\tdataset = MyDataset(data_file_name)\n",
        "\tdata_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\treturn data_loader"
      ],
      "metadata": {
        "id": "ePzOHWyC2wWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, data_loader, batch_size, tokenizer, model, device):\t\n",
        "\tbatch_counter = 0\n",
        "\tsum_loss = 0.0\n",
        "\n",
        "\tfor epoch in range(epochs):\n",
        "\t\tprint (f'Running {epoch+1} epoch')\n",
        "\n",
        "\t\tfor idx, txt in enumerate(data_loader):\n",
        "\t\t\ttxt = torch.tensor(tokenizer.encode(txt[0]))\n",
        "\t\t\ttxt = txt.unsqueeze(0).to(device)\n",
        "\t\t\toutputs = model(txt, labels=txt)\n",
        "\t\t\tloss, _ = outputs[:2]\n",
        "\t\t\tloss.backward()\n",
        "\t\t\tsum_loss += loss.data\n",
        "\n",
        "\t\t\tif idx%batch_size==0:\n",
        "\t\t\t\tbatch_counter += 1\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\tscheduler.step()\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\t\tmodel.zero_grad()\n",
        "\n",
        "\t\t\tif batch_counter == 10:\n",
        "\t\t\t\tprint(f\"Total Loss is {sum_loss}\") #printed after every 10*batch_size\n",
        "\t\t\t\tbatch_counter = 0\n",
        "\t\t\t\tsum_loss = 0.0\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "uzRpqU_C2ztz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, name):\n",
        "\t\"\"\"\n",
        "\tSummary:\n",
        "\t\tSaving model to the Disk\n",
        "\tParameters:\n",
        "\t\tmodel: Trained model object\n",
        "\t\tname: Name of the model to be saved\n",
        "\t\"\"\"\n",
        "\tprint (\"Saving model to Disk\")\n",
        "\ttorch.save(model.state_dict(), f\"{name}\")\n",
        "\treturn\n",
        "\n",
        "def load_models():\n",
        "\t\"\"\"\n",
        "\tSummary:\n",
        "\t\tLoading Pre-trained model\n",
        "\t\"\"\"\n",
        "\tprint ('Loading/Downloading GPT-2 Model')\n",
        "\ttokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "\tmodel = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "\treturn tokenizer, model"
      ],
      "metadata": {
        "id": "q1aSBELj24gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# parser = argparse.ArgumentParser(description='Arguments for training Text Augmentation model')\n",
        "\n",
        "# parser.add_argument('--epoch', default= 3,type=int, action='store', help='Number of epochs to run')\n",
        "# parser.add_argument('--warmup', default=300, type=int, action='store', help='Number of warmup steps to run')\n",
        "# parser.add_argument('--model_name', default='mymodel.pt', type=str, action='store', help='Name of the model file')\n",
        "# parser.add_argument('--data_file', default='mydata.csv', type=str, action='store', help='Name of the data file')\n",
        "# parser.add_argument('--batch', type=int, default=32, action='store', help='Batch size')\n",
        "# parser.add_argument('--learning_rate', default=3e-5, type=float, action='store', help='Learning rate for the model')\n",
        "# parser.add_argument('--max_len', default=200, type=int, action='store', help='Maximum length of sequence')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 3e-5\n",
        "WARMUP_STEPS = 300\n",
        "MAX_SEQ_LEN = 200\n",
        "MODEL_NAME = 'mymodel.pt'\n",
        "DATA_FILE = 'mydata.tsv'"
      ],
      "metadata": {
        "id": "8WhA1wtw278P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER, MODEL = load_models()\n",
        "LOADER = get_data_loader(DATA_FILE)\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = 'cuda'\n",
        "\n",
        "model = MODEL.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "21395f519bc7450b953df041ec8f2ef7",
            "a0eb24bb03fd4f1e980c9e12408afe3b",
            "7092bdb66e1e433fb224f8424bad1119",
            "87d6be9d3cf640c4a8f504c2f2afb29b",
            "c8cfefbc5e06422cae416be042cac1af",
            "13f231a754944d2881f3a8e40d056fb9",
            "3a5c2751d0cb47f6be5029cc3e670980",
            "56e0d449b3f14785a286d0e24692d88e",
            "3234ddf6680c4bc1a540ee82035145ba",
            "a955bfc90b424353a41efe8d5c514864",
            "8609499b3b8c46e099f789dff2d77f17",
            "00c5d7fd508d406683895ce05b8c2f32",
            "7aac417849474a4c9e22a7076ef49d55",
            "0d38dedc87df4381b7a0059b0a6c58da",
            "679f760adbce4a13bd8d60cacd3525fd",
            "efe161bb338643e8b9b03288f72f7ec5",
            "3b0c2ccc623247989576a29222958813",
            "10b33971cff54af7a27355c847fd9306",
            "04442ffa32b14d578c71875529583f01",
            "43dd6779d7de472cabc0e5802f1d9b28",
            "09d3bb43b0e141c79a03eab17b735418",
            "b5033bed5eac454f9221a699e70a522a",
            "9f525393d6de49a78b930d34623b6726",
            "829646d41f3b413493f6cf9eb26928b7",
            "feb448d53ae2439ea33a3f3ec40478ce",
            "3f64518b561f4ab3bb75168cc2885686",
            "08166a10f1c64d41a28c211df5dbe2ee",
            "bfe7d249ea3541beb251f8b440e0241f",
            "e4ef7de5a91244f5ac164746e14d0d0e",
            "2d56172c83c54a34bd0549234cc31275",
            "3ed1b2acca4e4a05b74dbdc7c7524753",
            "5b51c3f8939145aab9739ce3f060616c",
            "de78874af894491fbe77878c806bd4e5",
            "7821af971bcf401caef68ab1b9698db9",
            "93a13733429c4ee89fc7e7f0fcea105a",
            "217af3b2653644609f5d70e0a75a3c55",
            "e3d0872ce6854978bda788408a551fc7",
            "955815f452d14af1bf7980000b087e2a",
            "d6ef990594334f268bfd0b03c4833c36",
            "1d9cc72366954b508654a95b16859941",
            "ebfcd8ecce9040f98c75637524bf72e6",
            "0976ce8f740c48c6ac63cd7bf530785a",
            "5c26058c92214eeb806f70c71d84e722",
            "338eb17927f34ae78b333b2298cad9bd"
          ]
        },
        "id": "QQvWMLQ63pU9",
        "outputId": "28a8b2f0-497d-419a-9c3b-446dd1f6c187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading/Downloading GPT-2 Model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21395f519bc7450b953df041ec8f2ef7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00c5d7fd508d406683895ce05b8c2f32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f525393d6de49a78b930d34623b6726"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7821af971bcf401caef68ab1b9698db9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PFKFYIWt57_w",
        "outputId": "2b971d4d-8798-4f3d-8e82-a805d3df913c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)"
      ],
      "metadata": {
        "id": "FYxv38E84z3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(EPOCHS, LOADER, BATCH_SIZE, TOKENIZER, MODEL, DEVICE)\n",
        "save_model(model, MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaILcNL55MJi",
        "outputId": "5835312f-d225-4ca3-e83f-805c33ccc182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 1 epoch\n",
            "Total Loss is 1801.5150146484375\n",
            "Total Loss is 1941.7943115234375\n",
            "Total Loss is 1821.6468505859375\n",
            "Total Loss is 1700.4072265625\n",
            "Total Loss is 1544.7379150390625\n",
            "Total Loss is 1466.67724609375\n",
            "Total Loss is 1388.838134765625\n",
            "Total Loss is 1343.998291015625\n",
            "Total Loss is 1296.03857421875\n",
            "Total Loss is 1264.1611328125\n",
            "Total Loss is 1288.0946044921875\n",
            "Total Loss is 1267.6551513671875\n",
            "Total Loss is 1255.740478515625\n",
            "Total Loss is 1241.79248046875\n",
            "Total Loss is 1264.81298828125\n",
            "Total Loss is 1239.6658935546875\n",
            "Total Loss is 1230.7244873046875\n",
            "Saving model to Disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "inSe89KP_PW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_from_top_k_top_n(probs, k=50, p=0.8):\n",
        "  ind = np.argpartition(probs, -k)[-k:]\n",
        "  top_prob = probs[ind]\n",
        "  top_prob = {i: top_prob[idx] for idx,i in enumerate(ind)}\n",
        "  sorted_top_prob = {k: v for k, v in sorted(top_prob.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "  t=0\n",
        "  f=[]\n",
        "  pr = []\n",
        "  for k,v in sorted_top_prob.items():\n",
        "    t+=v\n",
        "    f.append(k)\n",
        "    pr.append(v)\n",
        "    if t>=p:\n",
        "      break\n",
        "  \n",
        "  top_prob = pr / np.sum(pr)\n",
        "  token_id = np.random.choice(f, 1, p = top_prob)\n",
        "  return int(token_id)"
      ],
      "metadata": {
        "id": "3dH77Dez5PIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(tokenizer, model, sentences, label):\n",
        "  with torch.no_grad():\n",
        "    for idx in range(sentences):\n",
        "      finished = False\n",
        "      cur_ids = torch.tensor(tokenizer.encode(label)).unsqueeze(0)\n",
        "      for i in range(100):\n",
        "        outputs = model(cur_ids, labels=cur_ids)\n",
        "        loss, logits = outputs[:2]\n",
        "\n",
        "        softmax_logits = torch.softmax(logits[0,-1], dim=0)\n",
        "\n",
        "        if i < 5:\n",
        "          n = 10\n",
        "        else:\n",
        "          n = 5\n",
        "        \n",
        "        next_token_id = choose_from_top_k_top_n(softmax_logits.numpy()) #top-k-top-n sampling\n",
        "        cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long() * next_token_id], dim = 1)\n",
        "        if next_token_id in tokenizer.encode('<|endoftext|>'):\n",
        "          finished = True\n",
        "          break\n",
        "      \n",
        "      if finished:\n",
        "        output_list = list(cur_ids.squeeze().numpy())\n",
        "        output_text = tokenizer.decode(output_list)\n",
        "        print (output_text)\n",
        "      else:\n",
        "        output_list = list(cur_ids.squeeze().numpy())\n",
        "        output_text = tokenizer.decode(output_list)\n",
        "        print (output_text)"
      ],
      "metadata": {
        "id": "KzuOKXEZ_2JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_models(model_name):\n",
        "\t\"\"\"\n",
        "\tSummary:\n",
        "\t\tLoading the trained model\n",
        "\t\"\"\"\n",
        "\tprint ('Loading Trained GPT-2 Model')\n",
        "\ttokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "\tmodel = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "\tmodel_path = model_name\n",
        "\tmodel.load_state_dict(torch.load(model_path))\n",
        "\treturn tokenizer, model"
      ],
      "metadata": {
        "id": "IyTSoFBI_7Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# parser = argparse.ArgumentParser(description='Arguments for inferencing Text Augmentation model')\n",
        "\n",
        "# parser.add_argument('--model_name', default='mymodel.pt', type=str, action='store', help='Name of the model file')\n",
        "# parser.add_argument('--sentences', type=int, default=5, action='store', help='Number of sentences in outputs')\n",
        "# parser.add_argument('--label', type=str, action='store', help='Label for which to produce text')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "SENTENCES = 100\n",
        "MODEL_NAME = 'mymodel.pt'\n",
        "LABEL = 'store'\n",
        "\n",
        "TOKENIZER, MODEL = load_models(MODEL_NAME)\n",
        "\n",
        "generate(TOKENIZER, MODEL, SENTENCES, LABEL)\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2KnFy4OJ_-bc",
        "outputId": "9ccefa6b-d818-4e03-f844-e0e0849b99b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Trained GPT-2 Model\n",
            "store:true},\n",
            "\n",
            "{\n",
            "\n",
            "{ \" id \" : \" 1 \",\n",
            "\n",
            "\" email \" : \" lisa@dw.com \",\n",
            "\n",
            "\" phone \" : \" +62 823452284 \",\n",
            "\n",
            "\" call xtd \" : \" 0861 003 4555 \",\n",
            "\n",
            "\" message \" : \" Ok ok ok ok ok?\",\n",
            "\n",
            "\" password \" : \"???? \",\n",
            "\n",
            "\" account \" :\n",
            "store:1.00p.<|endoftext|>\n",
            "store:  <|endoftext|>\n",
            "store:<|endoftext|>\n",
            "store:1\",\"display_in_home\":\"0\",\"title\":\"$250.00 for 1 month. Now $400.00 2 years. Unlimited phone calls, texts and data. This is a special Offer. Promo code BANQUET50. For details call 0300661250. 2 month minimum spend 8.50 per line 2 months min purchase £20.00 plus charge 2p per min use 20GB minimum. \",\"excludes_uplink\":\"No offers\n",
            "store: http://www.thegoldrushstore.com/storeid/2009575669901.aspx <|endoftext|>\n",
            "store: _______]/ <|endoftext|>\n",
            "store: A unique chance to win £20,000 in 2 years, £500 vouchers, free online and 4 years £100 travel rewards - so come on out! - Book Online <|endoftext|>\n",
            "store: $1.99/month for months 7 - 9, $2.99/month for months 10 - 12. Standard All Access Digital rate of $16.99/month begins after first year.\n",
            "\n",
            "*Introductory pricing schedule for 12 month: $0.99/month plus tax for first 3 months, $5.99/month for months 4 - 6, $10.99/month for months 7 - 9, $13.99/month for months 10 -\n",
            "store: true &amp;#trends: \"&amp;#title\": \"NEW TOP VIDEOS\"<|endoftext|>\n",
            "store:???????? <|endoftext|>\n",
            "store:true&start=15&end=150 <|endoftext|>\n",
            "store: <|endoftext|>\n",
            "store:0:0:1.0:2.0/1:2.0:80000.0000:90000:00000:00000000:1:1.0:0:0:2.0:00000002/1:2.0:0000.0000:00000.0000:2:2.0:80000.0000:40000:0000:00000:00000001/1:2.0:0000.0000:00000.0000:00000004/\n",
            "store: 0x200:50200.x6=1, 0x100:5200.x6=2, 0x50:4200.x6=3, 0x20:3000.x6=4, 0x10:1000.x6=5, 0x000:0000.x6=6, 0x000:0000.x7=7, 0x000:0000.x8=8, 0x000:0000.x9\n",
            "store: What's your current work location? <|endoftext|>\n",
            "store: 0x3e2c7e053dd50 <|endoftext|>\n",
            "store: $500 per month, 1-3 years* - $1000 per month, 1-3 years* <|endoftext|>\n",
            "store:  6c18a9da20c0b07a2c1f8c6c9a3e6f865d06f0db <|endoftext|>\n",
            "store: The great unknown from the bookseller's __________________\n",
            "\n",
            "p.s. can't i send them the file to the ebay shop? __________________<|endoftext|>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4d5a2bcad8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mTOKENIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOKENIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSENTENCES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-9519562f99f6>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(tokenizer, model, sentences, label)\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mcur_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    887\u001b[0m                 )\n\u001b[1;32m    888\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    890\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2dTn9bZDAgX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}